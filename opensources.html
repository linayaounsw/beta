<!DOCTYPE html>
<html lang="en">
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="description" content="insData, School of Computer Science and Engineering, UNSW Sydney">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, minimum-scale=1.0">
    <title>insData Group</title>

    <!-- Page styles -->
    <link rel="stylesheet"
          href="https://fonts.googleapis.com/css?family=Roboto:regular,bold,italic,thin,light,bolditalic,black,medium&amp;lang=en">
    <link rel="stylesheet" href="https://fonts.googleapis.com/icon?family=Material+Icons">
    <link rel="stylesheet" href="https://code.getmdl.io/1.3.0/material.min.css">
    <link rel="stylesheet" href="styles.css">
    <style>
        #view-source {
            position: fixed;
            display: block;
            right: 0;
            bottom: 0;
            margin-right: 40px;
            margin-bottom: 40px;
            z-index: 900;
        }
    </style>
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
</head>

<body>

<div class="demo-ribbon"
     style="background-image: url('images/others/OpenSource-Code-Pexels.jpeg');background-size: cover;"></div>
<div class="content">
    <div class="demo-container mdl-grid">
        <div class="mdl-cell mdl-cell--2-col"></div>
        <div class="mdl-shadow--2dp mdl-cell mdl-cell--8-col post">
            <div class="blog">
                <div class="section demo">
                    <h2><a name="demo">Research Demo and Open Source</a></h2>
                    <p>This series of demos demonstrate my recent progress in regards to <b>Brain Computer Interface
                        (BCI) system</b>. <br>
                        <br>An electroencephalography (EEG) based Brain Computer Interface (BCI) enables people to
                        communicate with the outside world by interpreting the EEG signals of their brains to interact
                        with intelligent devices such as wheelchairs and robots. More specifically, motor imagery EEG
                        (MI-EEG), which
                        reflects a subject’s active movement intent, has been attracting increasing attention in
                        developing an EEG-based BCI system. </p>
                    <ul>
                        <li data-sidenav-content-container="">
                            <h3><a id="Brain-Computer-Interface-Systems" data-sidenav="">Mind control smart living</a>
                            </h3>
                            <p>A simulated robot is navigated by our system, which learns user’s intent from EEG
                                recordings, to take a can of beverage from a table in the kitchen and put it in a table
                                in living room.<br><br> Reusable source code and dataset are provided in my github (<a
                                        href="https://github.com/xiangzhang1015">EEG-based-Control repository</a>).</p>

                            <p>
                                <iframe width="560" height="315" src="https://www.youtube.com/embed/VZYX1095Vkc"
                                        frameborder="0" allowfullscreen=""></iframe>
                            </p>
                            <p><b>Related Papers</b></p>
                            <ul>
                                <li data-pub-year="2017"><p><b>Xiang Zhang</b>, <span class="pub-me">Lina Yao</span>,
                                    Chaoran Huang, Quan Z. Sheng and Xianzhi Wang, <span class="pub-title"> <a
                                            href="https://arxiv.org/abs/1702.06830">Intent Recognition in Smart Living Through Deep Recurrent Neural Networks</a></span>.
                                    The 24th International Conference On Neural Information Processing (<a
                                            href="http://www.iconip2017.org/"><abbr
                                            title="The 24th International Conference On Neural Information Processing">ICONIP</abbr>
                                        2017</a>). Guangzhou, China, November 14-18, 2017.(Accepted, CORE Rank A)</p>
                                </li>

                                <li data-pub-year="2017"><p><b>Xiang Zhang</b>, <span class="pub-me">Lina Yao</span>,
                                    Dalin Zhang, Xianzhi Wang, Quan Z. Sheng and Tao Gu. <span class="pub-title"> <a
                                            href="https://arxiv.org/abs/1702.06830">Intent Recognition in Smart Living Through Deep Recurrent Neural Networks</a></span>.
                                    The 14th International Conference on Mobile and Ubiquitous Systems: Computing,
                                    Networking and Services (<a href="http://mobiquitous.org/2017/show/home">Mobiquitous
                                        2017</a>). Melbourne, Australia Nov 7 - 10, 2017. (Accepted, CORE Rank A)</p>
                                </li>
                            </ul>
                        </li>

                        <li data-sidenav-content-container="">
                            <h3><a id="Brain-Typing" data-sidenav="">Brain Typing System</a></h3>
                            <p>An online brain typing system is developed to convert user’s thoughts to texts, which
                                based on the high EEG (brainwave) signals classification accuracy. Motor disabled people
                                would benefit greatly from such a system to express their thoughts and communicate with
                                the outer world.<br>
                                <br><a href="https://drive.google.com/drive/folders/0B9MuJb6Xx2PIM0otakxuVHpkWkk">The
                                    EEG dataset can be accessed from this link.</a></p>

                            <p>
                                <iframe width="560" height="315" src="https://www.youtube.com/embed/Dc0StUPq61k"
                                        frameborder="0" allowfullscreen=""></iframe>
                            </p>
                            <p><b>Related Papers</b></p>
                            <ul>
                                <li data-pub-year="2018"><p><b>Xiang Zhang</b>, <span class="pub-me">Lina Yao</span>,
                                    Quan Z. Sheng, Salil S. Kanhere, Tao Gu and Dalin Zhang, <span class="pub-title"> <a
                                            href="https://arxiv.org/abs/1709.08820">Converting Your Thougts to Texts: Enabling Brain Typing via Deep Feature Learning of EEG Signals</a></span>.
                                    IEEE International Conference on Pervasive Computing and Communications (<a
                                            href="http://www.percom.org/">PerCom 2018</a>). Athens, Greece, March 19-23,
                                    2018. (Accepted, CORE Rank A*)</p></li>
                            </ul>

                        </li>

                    </ul>

                </div>

            </div>
        </div>
    </div>
    </post>
</div>

<script src="https://code.getmdl.io/1.3.0/material.min.js"></script>
<script>
    $("#navbar").load("navbar.html");
    $("#footer").load("footer.html");
</script>
</body>
</html>

