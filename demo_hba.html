<!DOCTYPE html>
<html lang="en">
<head>
    <title>D²</title>
    <meta charset="utf-8">
    <meta content="width=device-width, initial-scale=1, shrink-to-fit=no" name="viewport">
    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-148833726-1"></script>
    <script>
        window.dataLayer = window.dataLayer || [];

        function gtag() {
            dataLayer.push(arguments);
        }

        gtag('js', new Date());

        gtag('config', 'UA-148833726-1');
    </script>

    <link href="https://fonts.googleapis.com/css?family=Poppins:300,400,500,600,700,800,900" rel="stylesheet">

    <link href="css/open-iconic-bootstrap.min.css" rel="stylesheet">
    <link href="css/animate.css" rel="stylesheet">

    <link href="css/owl.carousel.min.css" rel="stylesheet">
    <link href="css/owl.theme.default.min.css" rel="stylesheet">
    <link href="css/magnific-popup.css" rel="stylesheet">

    <link href="css/aos.css" rel="stylesheet">

    <link href="css/ionicons.min.css" rel="stylesheet">

    <link href="css/bootstrap-datepicker.css" rel="stylesheet">
    <link href="css/jquery.timepicker.css" rel="stylesheet">


    <link href="css/flaticon.css" rel="stylesheet">
    <link href="css/icomoon.css" rel="stylesheet">
    <link href="css/style.css" rel="stylesheet">
</head>
<body>
<nav class="navbar navbar-expand-lg navbar-dark ftco_navbar bg-dark ftco-navbar-light" id="ftco-navbar">
    <div class="container">
        <a class="navbar-brand" href="index.html"><span>D²</span></a>
        <button aria-controls="ftco-nav" aria-expanded="false" aria-label="Toggle navigation" class="navbar-toggler"
                data-target="#ftco-nav" data-toggle="collapse" type="button">
            <span class="oi oi-menu"></span> Menu
        </button>

        <div class="collapse navbar-collapse" id="ftco-nav">
            <ul class="navbar-nav ml-auto">
                <li class="nav-item"><a class="nav-link" href="index.html">Home</a></li>
                <li class="nav-item"><a class="nav-link" href="publication.html">Publications</a></li>
                <li class="nav-item"><a class="nav-link" href="people.html">People</a></li>
                <li class="nav-item"><a class="nav-link" href="projects.html">Research Projects</a></li>
                <li class="nav-item active"><a class="nav-link" href="demos.html">Research Demos</a></li>
                <li class="nav-item"><a class="nav-link" href="contact.html">Contact</a></li>
                <li class="nav-item"><a class="nav-link" href="wiki.html">Group Wiki</a></li>
                <li class="nav-item"><a class="nav-link" href="media.html">Media</a></li>

            </ul>
        </div>
    </div>
</nav>
<!-- END nav -->

<section class="hero-wrap hero-wrap-2" data-stellar-background-ratio="0.5"
         style="background-image: url('images/demo_bg_hba.jpg');">
    <!--      <div class="overlay"></div>-->
    <div class="container">
        <div class="row no-gutters slider-text justify-content-center">
            <div class="col-md-9 ftco-animate pb-5 mb-5 text-center">
                <h1><br><br></h1>
                <h1 class="mb-3 bread">Research Demos</h1>
                <p class="breadcrumbs"><span class="mr-2"><a href="index.html">Home <i
                        class="ion-ios-arrow-forward"></i></a></span> <span class="mr-2">
                    <a href="demos.html">Research Demos<i class="ion-ios-arrow-forward"></i></a></span>
                    <span>HBA</span></p>
            </div>
        </div>
    </div>
</section>
<section class="ftco-section">
    <div class="container">
        <h2>Human Machine Interaction and robotics</h2>
        <h4>Human Machine Interaction</h4>
        <p>This video shows our preliminary work on human-machine interactions. The video demos an interactive robotic
            arm system. The robotic arm is set to track and follow the right hand of the subject in an opposite position
            in an interactive manner. The system utilized RBG and IR depth-finding camera for user behavior capturing
            and inexpensive 5-DOF robotic arms for interaction. </p>
        <center>
            <iframe width="560" height="315" src="https://www.youtube.com/embed/xxJhJKJtRXI" frameborder="0"
                    allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen>
            </iframe>
        </center>


        <h2>Human Activity Recognition</h2>
        <p>These demos showcase a series of novel approachs on device-free/wearable sensors, real-time activity
            recognition It can be potentially used in a wide range of applications such as Fall Detection, Ambulatory
            Monitoring, assistive living and abnormal activities detection etc.
            (<a href="//download.linayao.com/demos/PostureRec.avi">download</a>)</p>
        <center>
            <iframe allowfullscreen frameborder="0" height="315" src="//www.youtube.com/embed/yuf9lPlh4ig"
                    width="560"></iframe>
        </center>
        Related Papers
        <ul>
            <li>Xiang Zhang,Lina Yao, Chaoran Huang, Sen Wang, Mingkui Tan, Guodong Long, Can Wang, <strong>Multi-modality
                Sensor Data Classification with Selective Attention.</strong> The 27th International Joint Conference on
                Artificial Intelligence (IJCAI 2018), July 13-19 2018, Stockholm, Sweden.
            </li>
            <li>Kaixuan Chen,Lina Yao, Xianzhi Wang, Dalin Zhang，Tao Gu, Zhiwen Yu and Zheng Yang. <strong>Interpretable
                Recurrent Convolutional Neural Networks with Parallel Attentions for Multi-Modality Activity
                Modeling.</strong>International Joint Conference on Neural Networks (IJCNN 2018), Rio de Janeiro,
                Brazil, July 8 - 13, 2018.
            </li>
            <li>Kaixuan Chen,Lina Yao, Tao Gu, Zhiwen Yu, Xianzhi Wang and Dalin Zhang. Fullie and Wiselie: <strong>A
                Dual-Stream Recurrent Convolutional Attention Model for Activity Recognition</strong> arXiv
            </li>
            <li>Lina Yao, Quan Z. Sheng, Xue Li, Tao Gu, Mingkui Tan, Xianzhi Wang, Sen Wang and Wenjie Ruan. <strong>Compressive
                Representation for Device-Free Activity Recognition with Passive RFID Signal Strength.</strong> IEEE
                Transactions on Mobile Computing (TMC) , 2017
            </li>
            <li>Lina Yao, Feiping Nie, Quan Z. Sheng, Tao Gu, Xue Li, Sen Wang, <strong>Learning from Less for Better:
                Semi-Supervised Activity Recognition via Shared Structure Discovery.</strong> The 2016 ACM International
                Joint Conference on Pervasive and Ubiquitous Computing (UbiComp 2016). Heidelberg, Germany, September
                12-16, 2016.
            </li>
            <li>Lina Yao, Quan Z. Sheng, Xue Li, Tao Gu, Sen Wang, Wenjie Ruan and Wan Zou.<strong>Freedom: Online
                Activity Recognition via Dictionary-based Sparse Representation of RFID Sensing Data.</strong> The IEEE
                International Conference on Data Mining (ICDM 2015), Atlantic City, NJ, USA, November 14 - 17, 2015.
            </li>
            <li>Lina Yao, Quan Z. Sheng, Wenjie Ruan, Tao Gu, Xue Li, Nickolas J.G. Falkner, and Zhi Yang.<strong>RF-Care:
                Device-Free Posture Recognition for Elderly People Using Passive RFID Tag Array.</strong> The 12th
                International Conference on Mobile and Ubiquitous Systems: Computing, Networking and Services
                (MobiQuitous 2015). Coimbra, Portugal, July 22–24, 2015.
            </li>
        </ul>


        <h2>Some project demos from students who take research project in our group</h2>
        <ul>
            <li>
                <h3>"Activity Recognition Using Embedded Sensors in Smartphones", Bachelor CS (Advanced) Research
                    Project by Leon Chea, 2015.</h3>
                <p>This project explores the process of developing an Android system that utilises the embedded sensors
                    in a smartphone to recognise a number of common human actions and postures (Standing, Sitting,
                    Walking, Lying,...). Smartphones are a widely available commercial device and using it as a basis
                    for this project creates the possibility of future widespread usage and potential applications. The
                    sensors used include the accelerometer, gyroscope and magnetometer, all of which are commonly found
                    in modern smartphones.</p>
                <center>
                    <iframe allowfullscreen frameborder="0" height="315" src="https://www.youtube.com/embed/1xrKPgkuyfY"
                            width="560"></iframe>
                </center>
                <!--                <p>-->
                <!--                    <a href="//download.linayao.com/demos/Activity Recognition Using Embedded Sensors in Smartphones.mp4">download</a>-->
                <!--                </p>-->
            </li>
            <li>
                <h3>"Automatically Recognize Unhealthy Use of Smartphones", Bachelor CS (Advanced) Research Project by
                    Yuchieh (Henry) Yang, 2015.</h3>
                <p>This project explores an automated, objective and repeatable approach for assessing problematic usage
                    via collecting a wide range of phone usage data from smartphones, identify a number of usage
                    features that are relevant to this assessment, and build detection models automatically detecting
                    problematic use. For example, using phones in the darkness. </p>
                <center>
                    <iframe allowfullscreen frameborder="0" height="315" src="https://www.youtube.com/embed/T6pPi0KDKXY"
                            width="560"></iframe>
                </center>
                <!--                <p><a href="//download.linayao.com/demos/Automatically Recognize Unhealthy Use of Smartphones.mp4">download</a>-->
                <!--                </p>-->
            </li>
        </ul>
    </div>
</section>
<footer class="ftco-footer ftco-footer-2 ftco-section">
    <div class="container">
        <div class="row mb-5">
            <div class="col-md">
                <div class="ftco-footer-widget mb-4">
                    <a href="https://www.unsw.edu.au/"><img src="images/UNSW_reversed.png" style=" max-width:80%;"></a>
                </div>
            </div>
            <div class="col-md">
                <div class="ftco-footer-widget mb-4">
                    <div class="block-23 mb-3">
                        <ul>
                            <li><span class="icon icon-map-marker"></span><span class="text"> Building K17<br>
                        School of Computer Science and Engineering <br>
						UNSW Sydney, NSW 2052 <br>
						Australia
					</span></li>
                            <li><a href="#"><span class="icon icon-phone"></span><span
                                    class="text"> +61 2 9385 6556</span></a></li>
                            <li><a href="#"><span class="icon icon-envelope"></span><span class="text">lina.yao@unsw.edu.au</span></a>
                            </li>
                        </ul>
                    </div>
                </div>
            </div>
        </div>
        <div class="row">
            <div class="col-md-12 text-center">

                <p><!-- Link back to Colorlib can't be removed. Template is licensed under CC BY 3.0. -->
                    Copyright &copy;<script>document.write(new Date().getFullYear());</script>
                    All rights reserved | D² | This template is made with <i aria-hidden="true"
                                                                             class="icon-heart color-danger"></i> by <a
                            href="https://colorlib.com" target="_blank">Colorlib</a>
                    <!-- Link back to Colorlib can't be removed. Template is licensed under CC BY 3.0. --></p>
            </div>
        </div>
    </div>
</footer>


<!-- loader -->
<div class="show fullscreen" id="ftco-loader">
    <svg class="circular" height="48px" width="48px">
        <circle class="path-bg" cx="24" cy="24" fill="none" r="22" stroke="#eeeeee" stroke-width="4"/>
        <circle class="path" cx="24" cy="24" fill="none" r="22" stroke="#F96D00" stroke-miterlimit="10"
                stroke-width="4"/>
    </svg>
</div>


<script src="js/jquery.min.js"></script>
<script src="js/jquery-migrate-3.0.1.min.js"></script>
<script src="js/popper.min.js"></script>
<script src="js/bootstrap.min.js"></script>
<script src="js/jquery.easing.1.3.js"></script>
<script src="js/jquery.waypoints.min.js"></script>
<script src="js/jquery.stellar.min.js"></script>
<script src="js/owl.carousel.min.js"></script>
<script src="js/jquery.magnific-popup.min.js"></script>
<script src="js/aos.js"></script>
<script src="js/jquery.animateNumber.min.js"></script>
<script src="js/bootstrap-datepicker.js"></script>
<script src="js/scrollax.min.js"></script>
<script src="https://maps.googleapis.com/maps/api/js?key=AIzaSyBVWaKrjvy3MaE7SQ74_uJiULgl1JY0H2s&sensor=false"></script>
<script src="js/google-map.js"></script>
<script src="js/main.js"></script>

</body>
</html>